{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chlwldns00/NLP/blob/main/%EB%AC%B8%EC%84%9C%EA%B8%B0%EB%B0%98_%EB%8B%B5%EB%B3%80%EC%9D%84_%ED%95%B4%EC%A3%BC%EB%8A%94_QA_%EC%B1%97%EB%B4%87_Langchain%EC%82%AC%EC%9A%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 기업이나 교육기관 같은 곳에서 메뉴얼 기반으로(문서 기반) QA를 해주는 챗봇을 개발하는것이 목표\n",
        "\n",
        "\n",
        "------------------\n",
        "### 사용기술\n",
        "- QA ChatBot\n",
        "- LangChain\n",
        "- ChatGPT (gpt-3.5-turbo)\n",
        "- ChromaDB(벡터 데이터 베이스)\n",
        "\n"
      ],
      "metadata": {
        "id": "LAG2G551Vx4T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RRYSu48huSUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f24f86cb-ffe6-45f7-ba01-fb3a97e3dc93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.8/437.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain openai tiktoken chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 여러 문서\n",
        "\n",
        "> TechCrunch 기사(뉴스기사) 21개(txt파일)"
      ],
      "metadata": {
        "id": "XJTc_m1GWTfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/kairess/toy-datasets/raw/master/techcrunch-articles.zip\n",
        "!unzip -q techcrunch-articles.zip -d articles"
      ],
      "metadata": {
        "id": "l6XPLPVrqEaV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain\n",
        "\n",
        "OpenAI API Key\n",
        "\n",
        "https://platform.openai.com/account/api-keys"
      ],
      "metadata": {
        "id": "HqwsGJDhvAQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import DirectoryLoader"
      ],
      "metadata": {
        "id": "XHVE9uFb3Ajj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data load\n",
        "langchain의 데이터로더"
      ],
      "metadata": {
        "id": "9UcQKUId3X2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loader = TextLoader('single_text_file.txt') 단일문서일경우\n",
        "loader = DirectoryLoader('./articles', glob=\"*.txt\", loader_cls=TextLoader)\n",
        "\n",
        "documents = loader.load()\n",
        "\n",
        "len(documents)"
      ],
      "metadata": {
        "id": "PRSeXXc_3Ypj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6c8ed7-f5e7-4ebe-ef1d-5981e67da03c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gpt api에 입력토큰수를 초과할수 있으니 1000개로 쪼개주고 그다음 반복자를 200으로 설정\n"
      ],
      "metadata": {
        "id": "L39nElP4Wdu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) #article에 있는 내용을 천자 단위로 쪼개주고 반복(context로 선택시 context length가 초과될수있으므로)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "len(texts)"
      ],
      "metadata": {
        "id": "3__nT0D4Fkmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abfb42a9-fcde-4774-cfa3-2021c407ccbe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "233"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[2:4] #잘나오는지 테스트"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg6-9jwU4ja_",
        "outputId": "ea5035ba-b2fb-4489-ba4b-5e464f14deef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Go right ahead.\\n\\nSo as you might have noticed, Sergey has come back to do a little bit more on the artificial intelligence side of things, which is something he’s always been interested in; I would say historically, we’ve always had an interest in artificial intelligence. But that has escalated significantly over the past decade or so. The acquisition of DeepMind was a brilliant choice. And you can see some of the outcomes first of the spectacular stuff, like playing Go and winning. And then the more productive stuff, like figuring out how 200 million proteins are folded up.', metadata={'source': 'articles/05-05-vint-cerf-on-the-exhilarating-mix-of-thrill-and-hazard-at-the-frontiers-of-tech.txt'}),\n",
              " Document(page_content='Then there’s the large language models and the chatbots. And I think we’re still in a very peculiar period of time, where we’re trying to characterize what these things can and can’t do, and how they go off the rails, and how do you take advantage of them to do useful work? How do we get them to distinguish fact from fiction? All of that is in my view open territory, but then that’s always an exciting place to be — a place where nobody’s ever been before. The thrill of discovery and the risk of hazard create a fairly exciting mix — an exhilarating mix.\\n\\nYou gave a talk recently about, I don’t want to say the dangers of the large language models, but…\\n\\nWell, I did say there are hazards there. I was talking to a bunch of investment bankers, or VCs, and I said, you know, don’t try to sell stuff to your investors just because it’s flashy and shiny. Be cautious about going too fast and trying to apply it without figuring out how to put guardrails in place.', metadata={'source': 'articles/05-05-vint-cerf-on-the-exhilarating-mix-of-thrill-and-hazard-at-the-frontiers-of-tech.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Chroma DB\n",
        "\n",
        "1. 쪼갠 Text 를 Embbeding\n",
        "2. `db` 폴더에 데이터 저장\n",
        "3. DB 초기화\n",
        "4. `db` 폴더로부터 DB 로드"
      ],
      "metadata": {
        "id": "YsYsIy8F4cdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = 'db' #db라는 디렉토리\n",
        "\n",
        "embedding = OpenAIEmbeddings() #출처표시만 잘되는지 halluciantion테스트만 할거기에 openai임베딩 가져오기\n",
        "\n",
        "vectordb = Chroma.from_documents( #벡터db 설정 문서,임베딩방식,저장공간\n",
        "    documents=texts,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory)"
      ],
      "metadata": {
        "id": "Q_eTIZwf4Dk2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.persist() #vectordb초기화 메소드\n",
        "vectordb = None"
      ],
      "metadata": {
        "id": "uRfD_Te-47lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma(\n",
        "    persist_directory=persist_directory, #DB폴더에서 로드\n",
        "    embedding_function=embedding)"
      ],
      "metadata": {
        "id": "A-h1y_eAHmD-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a retriever"
      ],
      "metadata": {
        "id": "siLXR-XT0JoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever() #vectorDB의 검색기 정의\n",
        "retriever"
      ],
      "metadata": {
        "id": "6ObunFU30Lxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58efe09c-7848-4f8c-f6e6-3cc614ad0cb8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7e76e4aad600>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"What is Generative AI?\") #DB에서 이 질문의 답변과 연관된 문서 -> meta data: 를 찾아준다\n",
        "\n",
        "print(docs[0])\n",
        "for doc in docs:\n",
        "    print(doc.metadata[\"source\"])"
      ],
      "metadata": {
        "id": "cYA-H59u0Skn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4daaabfd-1ec6-49c3-cd81-1f116afc15f3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Developers can get in on the action too, building AI steps into workflows, giving them the option of tapping into external apps and large language models to build generative AI experiences themselves. Just last week the company made its updated developer experience generally available, and this should make it easier to incorporate generative AI into the platform in customized ways, Seaman says.\\n\\n“So this gives us the foundation to give users choice and flexibility to bring AI into their work in their business whenever they’re ready, and however they like. We’ve got 2,600 apps in the ecosystem right now, which includes a lot of the leading LLMs, and we see a lot of customers already choosing to integrate generative AI into Slack themselves,” he said.' metadata={'source': 'articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt'}\n",
            "articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt\n",
            "articles/05-03-nova-is-building-guardrails-for-generative-ai-content-to-protect-brand-integrity.txt\n",
            "articles/05-04-hugging-face-and-servicenow-release-a-free-code-generating-model.txt\n",
            "articles/05-03-spawning-lays-out-its-plans-for-letting-creators-opt-out-of-generative-ai-training.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결과를 K개 반환"
      ],
      "metadata": {
        "id": "_rHbFKUyjj-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n"
      ],
      "metadata": {
        "id": "5DziCXxcjrFK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"What is Generative AI?\")\n",
        "\n",
        "for doc in docs:\n",
        "    print(doc.metadata[\"source\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4Zr3tMkjuKo",
        "outputId": "26401a37-22a9-4fcd-ed46-b955ef4bc6ca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt\n",
            "articles/05-03-nova-is-building-guardrails-for-generative-ai-content-to-protect-brand-integrity.txt\n",
            "articles/05-04-hugging-face-and-servicenow-release-a-free-code-generating-model.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 검색 질답 체인 만들기"
      ],
      "metadata": {
        "id": "jlsKWlr7k8JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True)\n"
      ],
      "metadata": {
        "id": "vBe0epg6lGgH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_llm_response(llm_response):\n",
        "    print(llm_response['result'])\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "AwRM15t8lIr2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test -> 일단은 DB 텍스트 내에 있는 질문 + 형식도 텍스트 와 거의 동일하게 질문해보기\n"
      ],
      "metadata": {
        "id": "kKsE6g6dlNxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How much money did Pando raise?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_obisKTIlQ1K",
        "outputId": "f06a2c00-dc8a-47e5-96fd-d177a813f61d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Pando raised $30 million in a Series B round, bringing its total raised to $45 million.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLm response구조 보기"
      ],
      "metadata": {
        "id": "BVtf6NGplcZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GNJ8Swelfg3",
        "outputId": "7bea13b3-73f0-444b-9f54-441d607ded19"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'How much money did Pando raise?',\n",
              " 'result': ' Pando raised $30 million in a Series B round, bringing its total raised to $45 million.',\n",
              " 'source_documents': [Document(page_content='Signaling that investments in the supply chain sector remain robust, Pando, a startup developing fulfillment management technologies, today announced that it raised $30 million in a Series B round, bringing its total raised to $45 million.\\n\\nIron Pillar and Uncorrelated Ventures led the round, with participation from existing investors Nexus Venture Partners, Chiratae Ventures and Next47. CEO and founder Nitin Jayakrishnan says that the new capital will be put toward expanding Pando’s global sales, marketing and delivery capabilities.\\n\\n“We will not expand into new industries or adjacent product areas,” he told TechCrunch in an email interview. “Great talent is the foundation of the business — we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.”', metadata={'source': 'articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
              "  Document(page_content='The result of those major disruptions? The digital logistics market is estimated to climb to $46.5 billion by 2025, per Markets and Markets — up from $17.4 billion in 2019. Crunchbase reports that investors poured more than $7 billion in seed through growth-stage rounds globally for supply chain-focused startups from January to October 2022, nearly eclipsing 2021’s record-setting levels.\\n\\n“Pando has a strong balance sheet and profit and loss statement, with an eye on profitable growth,” Jayakrishnan said. “We’re are scaling operations in North America, Europe and India with marquee customer wins and a network of strong partners … Pando is well-positioned to ride this growth wave, and drive supply chain agility for the 2030 economy.”', metadata={'source': 'articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
              "  Document(page_content='But Pando has a compelling sales pitch, judging by its momentum. The company counts Fortune 500 manufacturers and retailers — including P&G, J&J, Valvoline, Castrol, Cummins, Siemens, Danaher and Accuride — among its customer base. Since the startup’s Series A in 2020, revenue has grown 8x while the number of customers has increased 5x, Jayakrishnan said.\\n\\nAsked whether he expects expansion to continue well into the future, given the signs of potential trouble on the horizon, Jayakrishnan seemed fairly optimistic. He pointed to a Deloitte survey that found that more than 70% of manufacturing companies have been impacted by supply chain disruptions in the past year, with 90% of those companies experiencing increased costs and declining productivity.', metadata={'source': 'articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'})]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_response['source_documents']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "_9gjvtPN4iFm",
        "outputId": "084d04a3-f4ed-459d-f894-b2b0ac2a31d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-813a35cfcd16>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mllm_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_documents'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'llm_response' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who led the round in Pando?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKUXOLXgllXI",
        "outputId": "59be53e2-c509-437d-b411-b22efadb6e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Iron Pillar and Uncorrelated Ventures led the round.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did Databricks acquire?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6ly4EtXlpeW",
        "outputId": "34083403-68b7-4626-c31b-8aaddd045b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Databricks acquired Okera, a data governance platform with a focus on AI.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n",
            "articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n",
            "articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Generative AI?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYWjLOnilrc_",
        "outputId": "ce117b3a-db3a-4ad7-c157-74181f5ca582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Generative AI is a type of Artificial Intelligence that is used to create new content from existing data. It can be used to automate tasks, generate content, and create new ideas.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt\n",
            "articles/05-03-nova-is-building-guardrails-for-generative-ai-content-to-protect-brand-integrity.txt\n",
            "articles/05-04-hugging-face-and-servicenow-release-a-free-code-generating-model.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is CMA?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSHewAgFltOY",
        "outputId": "ba07fc30-a52c-450c-e32a-b4e47914bf2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The CMA is the Competition and Markets Authority, a body in the U.K. responsible for enforcing competition and consumer protection law.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/05-04-cma-generative-ai-review.txt\n",
            "articles/05-04-cma-generative-ai-review.txt\n",
            "articles/05-04-cma-generative-ai-review.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqkR2KhUwJpQ",
        "outputId": "6b19f887-5616-46d7-bfee-9ca709b1cc3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/drive/MyDrive/Colab Notebooks/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name 'chlwldns00'\n",
        "!git config --global user.email 'chlwldns00@naver.com'"
      ],
      "metadata": {
        "id": "P_Hs-Ysj4_Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/Riffusion모델을 사용한 음악생성 인공지능 모델 테스트해보기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY4V2invwZ19",
        "outputId": "be4a8476-c800-4486-8456-df3c6b2c2770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 20] Not a directory: '/content/drive/MyDrive/Colab Notebooks/Riffusion모델을 사용한 음악생성 인공지능 모델 테스트해보기'\n",
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Wolb_ezz2No",
        "outputId": "7f2f7e2b-e924-4de0-e459-5042d1cfb652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add 문서기반 답변을 해주는 QA 챗봇-Langchain사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7QFjT_W2oeZ",
        "outputId": "ff37e101-4c11-4c11-c53e-c7c942893705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: pathspec '문서기반' did not match any files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git remote add origin  https://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@github.com/TmaxSoftProject/Basic_ChatBot_DBreference\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwI-SpN11Enl",
        "outputId": "b0d745a3-659a-4332-a6aa-a1ec49776eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error: remote origin already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote set-url origin https://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@github.com/TmaxSoftProject/Basic_ChatBot_DBreference"
      ],
      "metadata": {
        "id": "hWbr3WNjjRty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote -v\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UC_Zn1ui5u7",
        "outputId": "cdf0e93b-ac70-4552-ba1c-c8b616f21538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "origin\thttps://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@github.com/TmaxSoftProject/Basic_ChatBot_DBreference (fetch)\n",
            "origin\thttps://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@github.com/TmaxSoftProject/Basic_ChatBot_DBreference (push)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"firstcommit\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPRFCIT-5ncz",
        "outputId": "84c46b3b-0772-4f68-e71a-3b50ab18c8b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[master 8e02ed1] firstcommit\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin master\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF6c7P7O57Nf",
        "outputId": "b2dcd738-25a2-4b37-f4ce-cb959fe43c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 98, done.\n",
            "Counting objects:   1% (1/98)\rCounting objects:   2% (2/98)\rCounting objects:   3% (3/98)\rCounting objects:   4% (4/98)\rCounting objects:   5% (5/98)\rCounting objects:   6% (6/98)\rCounting objects:   7% (7/98)\rCounting objects:   8% (8/98)\rCounting objects:   9% (9/98)\rCounting objects:  10% (10/98)\rCounting objects:  11% (11/98)\rCounting objects:  12% (12/98)\rCounting objects:  13% (13/98)\rCounting objects:  14% (14/98)\rCounting objects:  15% (15/98)\rCounting objects:  16% (16/98)\rCounting objects:  17% (17/98)\rCounting objects:  18% (18/98)\rCounting objects:  19% (19/98)\rCounting objects:  20% (20/98)\rCounting objects:  21% (21/98)\rCounting objects:  22% (22/98)\rCounting objects:  23% (23/98)\rCounting objects:  24% (24/98)\rCounting objects:  25% (25/98)\rCounting objects:  26% (26/98)\rCounting objects:  27% (27/98)\rCounting objects:  28% (28/98)\rCounting objects:  29% (29/98)\rCounting objects:  30% (30/98)\rCounting objects:  31% (31/98)\rCounting objects:  32% (32/98)\rCounting objects:  33% (33/98)\rCounting objects:  34% (34/98)\rCounting objects:  35% (35/98)\rCounting objects:  36% (36/98)\rCounting objects:  37% (37/98)\rCounting objects:  38% (38/98)\rCounting objects:  39% (39/98)\rCounting objects:  40% (40/98)\rCounting objects:  41% (41/98)\rCounting objects:  42% (42/98)\rCounting objects:  43% (43/98)\rCounting objects:  44% (44/98)\rCounting objects:  45% (45/98)\rCounting objects:  46% (46/98)\rCounting objects:  47% (47/98)\rCounting objects:  48% (48/98)\rCounting objects:  50% (49/98)\rCounting objects:  51% (50/98)\rCounting objects:  52% (51/98)\rCounting objects:  53% (52/98)\rCounting objects:  54% (53/98)\rCounting objects:  55% (54/98)\rCounting objects:  56% (55/98)\rCounting objects:  57% (56/98)\rCounting objects:  58% (57/98)\rCounting objects:  59% (58/98)\rCounting objects:  60% (59/98)\rCounting objects:  61% (60/98)\rCounting objects:  62% (61/98)\rCounting objects:  63% (62/98)\rCounting objects:  64% (63/98)\rCounting objects:  65% (64/98)\rCounting objects:  66% (65/98)\rCounting objects:  67% (66/98)\rCounting objects:  68% (67/98)\rCounting objects:  69% (68/98)\rCounting objects:  70% (69/98)\rCounting objects:  71% (70/98)\rCounting objects:  72% (71/98)\rCounting objects:  73% (72/98)\rCounting objects:  74% (73/98)\rCounting objects:  75% (74/98)\rCounting objects:  76% (75/98)\rCounting objects:  77% (76/98)\rCounting objects:  78% (77/98)\rCounting objects:  79% (78/98)\rCounting objects:  80% (79/98)\rCounting objects:  81% (80/98)\rCounting objects:  82% (81/98)\rCounting objects:  83% (82/98)\rCounting objects:  84% (83/98)\rCounting objects:  85% (84/98)\rCounting objects:  86% (85/98)\rCounting objects:  87% (86/98)\rCounting objects:  88% (87/98)\rCounting objects:  89% (88/98)\rCounting objects:  90% (89/98)\rCounting objects:  91% (90/98)\rCounting objects:  92% (91/98)\rCounting objects:  93% (92/98)\rCounting objects:  94% (93/98)\rCounting objects:  95% (94/98)\rCounting objects:  96% (95/98)\rCounting objects:  97% (96/98)\rCounting objects:  98% (97/98)\rCounting objects: 100% (98/98)\rCounting objects: 100% (98/98), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (89/89), done.\n",
            "error: RPC failed; HTTP 408 curl 22 The requested URL returned error: 408\n",
            "send-pack: unexpected disconnect while reading sideband packet\n",
            "Writing objects: 100% (98/98), 480.76 MiB | 8.79 MiB/s, done.\n",
            "Total 98 (delta 13), reused 0 (delta 0), pack-reused 0\n",
            "fatal: the remote end hung up unexpectedly\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global --list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3JsyyAZ9oIB",
        "outputId": "88280c75-93fb-4b0a-88ce-3131eb97b165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user.name=chlwldns00\n",
            "user.email=chlwldns00@naver.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7cKpggupGf10"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}